{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830508474576272"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state = 123456)\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "X_lda = lda.fit(X_train, Y_train)\n",
    "Y_pred1 = lda.predict(X_test)\n",
    "Y_pred1\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc1 = accuracy_score(Y_test, Y_pred1)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627118644067796"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state = 123456)\n",
    "\n",
    "import pandas as pd\n",
    "X_wineDF = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
    "Y_wineDF = pd.Categorical.from_codes(wine.target, wine.target_names)\n",
    "wineDF = X_wineDF.join(pd.Series(Y_wineDF, name = 'Class'))\n",
    "wineDF.head()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors':range(1,30)}\n",
    "GS = GridSearchCV(KNeighborsClassifier(), param_grid, scoring = 'accuracy')\n",
    "GS.fit(X_train, Y_train)\n",
    "\n",
    "GS.best_params_\n",
    "\n",
    "GS.best_score_\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "KNNClassifier = KNeighborsClassifier(n_neighbors=16)\n",
    "KNNClassifier.fit(X_train, Y_train)\n",
    "Y_pred2 = KNNClassifier.predict(X_test)\n",
    "acc2 = accuracy_score(Y_test, Y_pred2)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830508474576272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaledtrain = scaler.transform(X_train)\n",
    "X_scaledtest = scaler.transform(X_test)\n",
    "mlgr = LogisticRegression(multi_class='auto')\n",
    "mlgr.fit(X_scaledtrain, Y_train)\n",
    "\n",
    "Y_pred3 = mlgr.predict(X_scaledtest)\n",
    "Y_pred3\n",
    "\n",
    "acc3 = accuracy_score(Y_test, Y_pred3)\n",
    "acc3\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "acc3 = accuracy_score(Y_test, Y_pred3)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, tree   # The tree module contains Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=3)\n",
    "DT.fit(X_train, Y_train)\n",
    "tree.plot_tree(DT)\n",
    "\n",
    "Y_pred4 = DT.predict(X_test)\n",
    "acc4 = accuracy_score(Y_pred4, Y_test)\n",
    "acc4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830508474576272"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc1, acc2, acc3, acc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The maximum accuray is obtained in the Linear Discriminant Analysis Approach.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "data=datasets.load_diabetes()\n",
    "data\n",
    "\n",
    "x=data.data\n",
    "x\n",
    "y=data.target\n",
    "y\n",
    "kk=np.corrcoef(x.T,y)[:,-1]\n",
    "kk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y,x[:,2])\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=1322222)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ff=LinearRegression()\n",
    "model=ff.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "mean_squared_error(y_test,y_pred)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "bc=datasets.load_breast_cancer()\n",
    "print(bc.DESCR)\n",
    "\n",
    "x=bc.data\n",
    "y=1-bc.target\n",
    "\n",
    "kk=np.corrcoef(x.T,y)[:,-1]\n",
    "kk\n",
    "\n",
    "sns.boxplot(y,x[:,2])\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "kk=LogisticRegression()\n",
    "kf=KFold(10,shuffle =True)\n",
    "cnv=cross_validate(kk,x,y,cv=kf)\n",
    "score=cnv['test_score']\n",
    "score\n",
    "\n",
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB   \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()   \n",
    "iris.feature_names\n",
    "\n",
    "X = iris.data[:, [0, 2]]      \n",
    "y = iris.target\n",
    "\n",
    "\n",
    "gnb = GaussianNB()  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "y_train\n",
    "\n",
    "X_train\n",
    "\n",
    "y_pred\n",
    "\n",
    "X\n",
    "\n",
    "y\n",
    "\n",
    "y_test\n",
    "\n",
    "X_test\n",
    "\n",
    "x0_min, x0_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x1_min, x1_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "x0, x1 = np.meshgrid(np.arange(x0_min, x0_max, 0.1),\n",
    "                     np.arange(x1_min, x1_max, 0.1))\n",
    "yy = gnb.predict(np.c_[x0.ravel(), x1.ravel()])\n",
    "yy = yy.reshape(x0.shape)\n",
    "\n",
    "CS = plt.contourf(x0, x1, yy, levels = [-1, 0, 1, 2])\n",
    "art, lbl = CS.legend_elements()    \n",
    "lbl = iris.target_names           \n",
    "plt.legend(art,lbl, edgecolor = \"k\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y,s=20, edgecolor='k')\n",
    "plt.show()\n",
    "\n",
    "u = np.array([1, 2, 3])\n",
    "v = np.array([2, 4, 6])\n",
    "uu, vv = np.meshgrid(u, v)\n",
    "\n",
    "uu\n",
    "\n",
    "vv\n",
    "\n",
    "uu.ravel()\n",
    "\n",
    "np.c_[uu.ravel(), vv.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=50, n_features=2, centers=2)\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel=\"linear\")\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy = %0.4f'%np.mean(y_pred == y_test))\n",
    "\n",
    "\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
    "\n",
    "ax = plt.gca() \n",
    "xlim = ax.get_xlim()    \n",
    "ylim = ax.get_ylim()     \n",
    "\n",
    "\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "\n",
    "Z = svc.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(\n",
    "    XX, YY, Z, levels=[-1, 0, 1], alpha=0.5, colors=\"k\", linestyles=[\"--\", \"-\", \"--\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    svc.support_vectors_[:, 0],\n",
    "    svc.support_vectors_[:, 1],\n",
    "    s=100,linewidth=1,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "svc.decision_function(X_test)\n",
    "\n",
    "svc.predict(X_test)\n",
    "\n",
    "svc.support_vectors_\n",
    "\n",
    "svc.decision_function(svc.support_vectors_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
